{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee29d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (60000, 784)\n",
      "Test shape: (5000, 784)\n",
      "Dig-MNIST shape: (10240, 784)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "dig_df = pd.read_csv('../data/Dig-MNIST.csv')\n",
    "\n",
    "\n",
    "pixel_columns = [col for col in train_df.columns if col.startswith(\"pixel\")]\n",
    "\n",
    "X = train_df[pixel_columns].values / 255.0\n",
    "y = train_df[\"label\"].values\n",
    "X_test = test_df[pixel_columns].values / 255.0\n",
    "\n",
    "X_dig = dig_df[pixel_columns].values / 255.0\n",
    "y_dig = dig_df[\"label\"].values\n",
    "\n",
    "print(\"Train shape:\", X.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"Dig-MNIST shape:\", X_dig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1bd747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Training model: LGBM_base\n",
      "  üîÅ Fold 1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 95180\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 619\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.117958\n",
      "[100]\tvalid_0's multi_logloss: 0.055543\n",
      "[150]\tvalid_0's multi_logloss: 0.0463987\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tvalid_0's multi_logloss: 0.04576\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's multi_logloss: 0.0454856\n",
      "  üîÅ Fold 2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 94756\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 620\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.121314\n",
      "[100]\tvalid_0's multi_logloss: 0.0593777\n",
      "[150]\tvalid_0's multi_logloss: 0.0506252\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's multi_logloss: 0.0502423\n",
      "  üîÅ Fold 3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 94849\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 619\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.121636\n",
      "[100]\tvalid_0's multi_logloss: 0.0604091\n",
      "[150]\tvalid_0's multi_logloss: 0.0514219\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tvalid_0's multi_logloss: 0.0508584\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's multi_logloss: 0.0504985\n",
      "  üîÅ Fold 4\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 95096\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 618\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.120483\n",
      "[100]\tvalid_0's multi_logloss: 0.0612115\n",
      "[150]\tvalid_0's multi_logloss: 0.0545314\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's multi_logloss: 0.0543835\n",
      "  üîÅ Fold 5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 94858\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 618\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.122646\n",
      "[100]\tvalid_0's multi_logloss: 0.0615754\n",
      "[150]\tvalid_0's multi_logloss: 0.0519155\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tvalid_0's multi_logloss: 0.0503542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's multi_logloss: 0.050217\n",
      "‚úÖ Model: LGBM_base\n",
      "   ‚Üí Avg Val Accuracy: 0.9858\n",
      "   ‚Üí Dig-MNIST Accuracy: 0.6751\n",
      "\n",
      "üîß Training model: LGBM_deep_wide\n",
      "  üîÅ Fold 1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.148427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 95180\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 619\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.231757\n",
      "[100]\tvalid_0's multi_logloss: 0.080636\n",
      "[150]\tvalid_0's multi_logloss: 0.0551502\n",
      "[200]\tvalid_0's multi_logloss: 0.0499875\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's multi_logloss: 0.049773\n",
      "  üîÅ Fold 2\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 94756\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 620\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.234187\n",
      "[100]\tvalid_0's multi_logloss: 0.0850117\n",
      "[150]\tvalid_0's multi_logloss: 0.0605503\n",
      "[200]\tvalid_0's multi_logloss: 0.0561319\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[228]\tvalid_0's multi_logloss: 0.0557241\n",
      "  üîÅ Fold 3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.150462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 94849\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 619\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.233594\n",
      "[100]\tvalid_0's multi_logloss: 0.0849166\n",
      "[150]\tvalid_0's multi_logloss: 0.0616904\n",
      "[200]\tvalid_0's multi_logloss: 0.0578259\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's multi_logloss: 0.0576194\n",
      "  üîÅ Fold 4\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.144825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 95096\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 618\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.23513\n",
      "[100]\tvalid_0's multi_logloss: 0.0848563\n",
      "[150]\tvalid_0's multi_logloss: 0.0619046\n",
      "[200]\tvalid_0's multi_logloss: 0.0584369\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's multi_logloss: 0.0583967\n",
      "  üîÅ Fold 5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 94858\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 618\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.234873\n",
      "[100]\tvalid_0's multi_logloss: 0.0862162\n",
      "[150]\tvalid_0's multi_logloss: 0.0612251\n",
      "[200]\tvalid_0's multi_logloss: 0.0558897\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's multi_logloss: 0.0557712\n",
      "‚úÖ Model: LGBM_deep_wide\n",
      "   ‚Üí Avg Val Accuracy: 0.9845\n",
      "   ‚Üí Dig-MNIST Accuracy: 0.6579\n",
      "\n",
      "üîß Training model: LGBM_fast\n",
      "  üîÅ Fold 1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.148071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 95180\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 619\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.0710805\n",
      "[100]\tvalid_0's multi_logloss: 0.0467402\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\tvalid_0's multi_logloss: 0.0436486\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's multi_logloss: 0.0435567\n",
      "  üîÅ Fold 2\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.155577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 94756\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 620\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.0761108\n",
      "[100]\tvalid_0's multi_logloss: 0.0515808\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\tvalid_0's multi_logloss: 0.0488972\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's multi_logloss: 0.0488244\n",
      "  üîÅ Fold 3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.151063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 94849\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 619\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.0737542\n",
      "[100]\tvalid_0's multi_logloss: 0.0488089\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\tvalid_0's multi_logloss: 0.0457965\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's multi_logloss: 0.0457507\n",
      "  üîÅ Fold 4\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.150428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 95096\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 618\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.0752732\n",
      "[100]\tvalid_0's multi_logloss: 0.0537507\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 0.0525933\n",
      "  üîÅ Fold 5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 94858\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 618\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.0762748\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.0515054\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\tvalid_0's multi_logloss: 0.047956\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's multi_logloss: 0.0477246\n",
      "‚úÖ Model: LGBM_fast\n",
      "   ‚Üí Avg Val Accuracy: 0.9863\n",
      "   ‚Üí Dig-MNIST Accuracy: 0.6822\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        \"n_estimators\": 1000,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 64,\n",
    "        \"max_depth\": 10,\n",
    "        \"subsample\": 1.0,\n",
    "        \"colsample_bytree\": 1.0,\n",
    "        \"model_name\": \"LGBM_base\"\n",
    "    },\n",
    "    {\n",
    "        \"n_estimators\": 1000,\n",
    "        \"learning_rate\": 0.03,\n",
    "        \"num_leaves\": 127,\n",
    "        \"max_depth\": 15,\n",
    "        \"subsample\": 0.9,\n",
    "        \"colsample_bytree\": 0.9,\n",
    "        \"model_name\": \"LGBM_deep_wide\"\n",
    "    },\n",
    "    {\n",
    "        \"n_estimators\": 500,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"num_leaves\": 31,\n",
    "        \"max_depth\": 7,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"model_name\": \"LGBM_fast\"\n",
    "    },\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for config in param_grid:\n",
    "    print(f\"\\nüîß Training model: {config['model_name']}\")\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros((X_test.shape[0], 10))\n",
    "    dig_preds = np.zeros((X_dig.shape[0], 10))\n",
    "    val_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"   Fold {fold+1}\")\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = lgb.LGBMClassifier(\n",
    "            objective=\"multiclass\",\n",
    "            num_class=10,\n",
    "            random_state=42,\n",
    "            **{k: v for k, v in config.items() if k != \"model_name\"}\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric=\"multi_logloss\",\n",
    "            callbacks=[early_stopping(20), log_evaluation(50)]\n",
    "        )\n",
    "\n",
    "        val_preds = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, val_preds)\n",
    "        val_scores.append(acc)\n",
    "\n",
    "        test_preds += model.predict_proba(X_test) / skf.n_splits\n",
    "        dig_preds += model.predict_proba(X_dig) / skf.n_splits\n",
    "\n",
    "    final_preds = np.argmax(test_preds, axis=1)\n",
    "    dig_final_preds = np.argmax(dig_preds, axis=1)\n",
    "    dig_acc = accuracy_score(y_dig, dig_final_preds)\n",
    "\n",
    "    print(f\" Model: {config['model_name']}\")\n",
    "    print(f\"   ‚Üí Avg Val Accuracy: {np.mean(val_scores):.4f}\")\n",
    "    print(f\"   ‚Üí Dig-MNIST Accuracy: {dig_acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"model_name\": config[\"model_name\"],\n",
    "        \"val_acc\": np.mean(val_scores),\n",
    "        \"dig_acc\": dig_acc,\n",
    "        \"submission\": final_preds\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f490fd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best model: LGBM_fast\n",
      " Submission file saved!\n",
      "\n",
      "üìä Model Comparison:\n",
      "Model Name           Val Accuracy    Dig-MNIST Accuracy  \n",
      "LGBM_base            0.9858          0.6751              \n",
      "LGBM_deep_wide       0.9845          0.6579              \n",
      "LGBM_fast            0.9863          0.6822              \n"
     ]
    }
   ],
   "source": [
    "best_model = max(results, key=lambda x: x[\"val_acc\"])\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": np.arange(1, len(best_model[\"submission\"]) + 1),\n",
    "    \"label\": best_model[\"submission\"]\n",
    "})\n",
    "submission.to_csv(\n",
    "    \"../submissions/mldl_competition3_sharifbek_submission1.csv\", index=False)\n",
    "\n",
    "print(f\"\\n Best model: {best_model['model_name']}\")\n",
    "print(\" Submission file saved!\")\n",
    "\n",
    "print(\"\\nüìä Model Comparison:\")\n",
    "print(\"{:<20} {:<15} {:<20}\".format(\n",
    "    \"Model Name\", \"Val Accuracy\", \"Dig-MNIST Accuracy\"))\n",
    "for r in results:\n",
    "    print(\"{:<20} {:<15.4f} {:<20.4f}\".format(\n",
    "        r[\"model_name\"], r[\"val_acc\"], r[\"dig_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eccb357f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook mldl_competition3_sharifbek_submission1.ipynb to html\n",
      "[NbConvertApp] Writing 328729 bytes to mldl_competition3_sharifbek_submission1.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html \"mldl_competition3_sharifbek_submission1.ipynb\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
